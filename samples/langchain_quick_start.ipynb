{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "h-OOsugXAtsV"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbF2F2miAT4a"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googleapis/langchain-google-spanner-python/blob/main/samples/langchain_quick_start.ipynb)\n",
    "\n",
    "---\n",
    "# **Introduction**\n",
    "\n",
    "In this codelab, you'll learn how to create a powerful interactive generative AI application using Retrieval Augmented Generation powered by [Spanner](https://cloud.google.com/spanner) and [LangChain](https://www.langchain.com/). We will be creating an application grounded in a [Netflix Movie dataset](https://www.kaggle.com/datasets/shivamb/netflix-shows), allowing you to interact with movie data in exciting new ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma6pEng3ypbA"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "* A basic understanding of the Google Cloud Console\n",
    "* Basic skills in command line interface and Google Cloud shell\n",
    "* Basic python knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzDgqJHgysy1"
   },
   "source": [
    "## What you'll learn\n",
    "\n",
    "* How to deploy a Spanner instance\n",
    "* How to use Spanner as a VectorStore\n",
    "* How to use Spanner as a DocumentLoader\n",
    "* How to use Spanner for ChatHistory storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbcZUjT1yvTq"
   },
   "source": [
    "## What you'll need\n",
    "* A Google Cloud Account and Google Cloud Project\n",
    "* A web browser such as [Chrome](https://www.google.com/chrome/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHdR4fF3vLWA"
   },
   "source": [
    "# **Setup and Requirements**\n",
    "\n",
    "In the following instructions you will learn to:\n",
    "1. Install required dependencies for our application\n",
    "2. Set up authentication for our project\n",
    "3. Set up a Spanner Instance\n",
    "4. Import the data used by our application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy9KqgPQ4GBi"
   },
   "source": [
    "## Install dependencies\n",
    "First you will need to install the dependencies needed to run this demo app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-spanner in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (0.8.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.1.25 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-spanner) (0.3.59)\n",
      "Requirement already satisfied: langchain-community<1.0.0,>=0.0.18 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-spanner) (0.3.23)\n",
      "Requirement already satisfied: google-cloud-spanner<4.0.0,>=3.41.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-spanner) (3.57.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-spanner) (2.11.4)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (2.24.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=1.4.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (2.4.3)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (0.14.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (1.26.1)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (0.5.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (6.31.0rc2)\n",
      "Requirement already satisfied: grpc-interceptor>=0.15.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (0.15.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (1.70.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (2.40.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (1.72.0rc1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (1.72.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (4.9.1)\n",
      "Collecting langchain<1.0.0,>=0.3.24 (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (0.1.147)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (0.9.0)\n",
      "Collecting langchain-core<1.0.0,>=0.1.25 (from langchain-google-spanner)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<1.0.0,>=0.3.24->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-community<1.0.0,>=0.0.18->langchain-google-spanner)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.1.25->langchain-google-spanner) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.1.25->langchain-google-spanner) (4.13.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.1.25->langchain-google-spanner) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.1.25->langchain-google-spanner) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.1->langchain-google-spanner) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.1->langchain-google-spanner) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.1->langchain-google-spanner) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (2.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0->google-cloud-spanner<4.0.0,>=3.41.0->langchain-google-spanner) (0.6.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<1.0.0,>=0.0.18->langchain-google-spanner) (1.3.1)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Installing collected packages: langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K  Attempting uninstall: langsmith\n",
      "\u001b[2K    Found existing installation: langsmith 0.1.147\n",
      "\u001b[2K    Uninstalling langsmith-0.1.147:\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.1.147\n",
      "\u001b[2K  Attempting uninstall: langchain-core\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.59\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.59:\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.59━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain-text-splitters━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-text-splitters 0.3.8[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-text-splitters-0.3.8:━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-text-splitters-0.3.8━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain 0.3.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-0.3.0:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [langchain]]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.3.00m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [langchain]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [langchain]/4\u001b[0m [langchain]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-0.3.27 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.3.45\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain==0.3\n",
      "  Using cached langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-google-vertexai in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (2.0.24)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (3.11.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (0.3.11)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (2.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain==0.3) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3) (1.20.0)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3)\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.73-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3) (3.0.0)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3) (1.0.0)\n",
      "Requirement already satisfied: anyio in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3) (0.16.0)\n",
      "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pip>=25.2 (from langchain-text-splitters<0.4.0,>=0.3.0->langchain==0.3)\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.3) (2.4.0)\n",
      "Requirement already satisfied: bottleneck<2.0.0,>=1.4.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-vertexai) (1.4.2)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.92.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-vertexai) (1.109.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-vertexai) (2.19.0)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-vertexai) (0.4.0)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.6 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-vertexai) (2.10.2)\n",
      "Requirement already satisfied: pyarrow<20.0.0,>=19.0.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-vertexai) (19.0.1)\n",
      "Requirement already satisfied: validators<1,>=0.22.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from langchain-google-vertexai) (0.35.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (2.40.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (6.31.0rc2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (3.31.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (2.1.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (1.30.0)\n",
      "Requirement already satisfied: docstring_parser<1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (1.72.0rc1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (1.72.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai) (1.7.1)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (1.17.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.92.0->langchain-google-vertexai) (0.6.1)\n",
      "Using cached langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
      "Downloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K  Attempting uninstall: langsmith\n",
      "\u001b[2K    Found existing installation: langsmith 0.3.45\n",
      "\u001b[2K    Uninstalling langsmith-0.3.45:\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.3.45\n",
      "\u001b[2K  Attempting uninstall: langchain-core\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.76\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.76:\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.76\n",
      "\u001b[2K  Attempting uninstall: langchain-text-splitters━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-text-splitters 0.3.110m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-text-splitters-0.3.11:━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-text-splitters-0.3.11\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain 0.3.27━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-0.3.27:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.3.27━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [langchain]/4\u001b[0m [langchain]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.3.23 requires langchain<1.0.0,>=0.3.24, but you have langchain 0.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.3.0 langchain-core-0.3.63 langchain-text-splitters-0.3.8 langsmith-0.1.147\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-google-spanner\n",
    "# Install additional dependencies\n",
    "%pip install langchain==0.3 langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeUbHclxw7_l"
   },
   "source": [
    "## Authenticate to Google Cloud within Colab\n",
    "In order to access your Google Cloud Project from this notebook, you will need to Authenticate as an IAM user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=5KFl73uDcsf3WdVAMc0I1ff20UC3uO&access_type=offline&code_challenge=HYXwT0TEemP5gzZIXIz2lXEojp0TFvRI47_2jEa92Zo&code_challenge_method=S256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCiNGP1Qxd6x"
   },
   "source": [
    "## Connect Your Google Cloud Project\n",
    "Time to connect your Google Cloud Project to this notebook so that you can leverage Google Cloud from within Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
    "\n",
    "# Please fill in these values.\n",
    "project_id = \"your_project_id\"  # @param {type:\"string\"}\n",
    "\n",
    "# Quick input validations.\n",
    "assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n",
    "\n",
    "# Configure gcloud.\n",
    "!gcloud config set project {project_id}\n",
    "%env GOOGLE_CLOUD_PROJECT={project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-oqMC5Ox-ZM"
   },
   "source": [
    "## Configure Your Google Cloud Project\n",
    "Configure the following in your Google Cloud Project.\n",
    "\n",
    "1. IAM principal (user, service account, etc.) with the\n",
    "[Spanner Database User][client-role] role.\n",
    "\n",
    "> The user logged into this notebook will be used as the IAM principal and will be granted the Spanner Database Use  role.\n",
    "\n",
    "[client-role]: https://cloud.google.com/spanner/docs/iam#sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grant Cloud Spanner databaseUser role to authenticated user\n",
    "current_user = !gcloud auth list --filter=status:ACTIVE --format=\"value(account)\"\n",
    "\n",
    "!gcloud projects add-iam-policy-binding {project_id} \\\n",
    "  --member=user:{current_user[0]} \\\n",
    "  --role=\"roles/spanner.databaseUser\" \\\n",
    "  --condition=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "2. Enable the APIs for Spanner and Vertex AI within your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable GCP services\n",
    "!gcloud services enable spanner.googleapis.com aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gn8g7-wCyZU6"
   },
   "source": [
    "## Set up Spanner\n",
    "You will need a **Spanner** instance for the following stages of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T616pEOUygYQ"
   },
   "source": [
    "### Create a Spanner Instance & Database\n",
    "Running the below cell will verify the existence of the Spanner instance & database and also create a new instance and database if one does not exist.\n",
    "\n",
    "> ⏳ - Creating a Spanner instance & database ay take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown Please fill in the both the Google Cloud region and name of your Cloud Spanner instance. Once filled in, run the cell.\n",
    "\n",
    "# Please fill in these values.\n",
    "region = \"us-central1\" #@param {type:\"string\"}\n",
    "instance_id = \"YOUR-INSTANCE-NAME\" #@param {type:\"string\"}\n",
    "database_id = \"YOUR-DB-NAME\" #@param {type:\"string\"}\n",
    "# Quick input validations.\n",
    "assert region, \"⚠️ Please provide a Google Cloud region\"\n",
    "assert instance_id, \"⚠️ Please provide the name of your instance\"\n",
    "assert database_id, \"⚠️ Please provide the name of your database\"\n",
    "\n",
    "# check if Cloud Spanner instance exists in the provided region\n",
    "instance = !gcloud spanner instances describe {instance_id}\n",
    "\n",
    "if 'ERROR' in instance[0]:\n",
    "  print(\"Instance not found\")\n",
    "  print(\"Creating new Cloud Spanner instance...\")\n",
    "  !gcloud spanner instances create {instance_id} \\\n",
    "    --config={config} --nodes=4 --description={instance_id}\n",
    "\n",
    "database = !gcloud spanner databases describe {database_id} --instance={instance_id}\n",
    "\n",
    "if 'ERROR' in database[0]:\n",
    "  print(\"Database not found\")\n",
    "  print(\"Creating new Cloud Spanner database...\")\n",
    "  !gcloud spanner databases create {database_id} \\\n",
    "    --instance={instance_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdolCWyatZmG"
   },
   "source": [
    "## Import data to your database\n",
    "\n",
    "Now that you have your database, you will need to import data! We will be using a [Netflix Dataset from Kaggle](https://www.kaggle.com/datasets/shivamb/netflix-shows). Here is what the data looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36-FBKzJ-tLa"
   },
   "source": [
    "| show_id | type    | title                | director         | cast                                                                                                                                                  | country       | date_added        | release_year | rating | duration  | listed_in                                    | description                                                                                                                                                                           |\n",
    "|---------|---------|----------------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|-------------------|--------------|--------|-----------|----------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| s1      | Movie   | Dick Johnson Is Dead | Kirsten Johnson  |                                                                                                                                                        | United States | September 25, 2021 | 2020         | PG-13  | 90 min    | Documentaries                                | As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.                              |\n",
    "| s2      | TV Show | Blood & Water        |                  | Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba, Dillon Windvogel, Natasha Thahane, Arno Greeff, Xolile Tshabalala, Getmore Sithole, Cindy Mahlangu, Ryle De Morny, Greteli Fincham, Sello Maake Ka-Ncube, Odwa Gwanya, Mekaila Mathys, Sandi Schultz, Duane Williams, Shamilla Miller, Patrick Mofokeng | South Africa  | September 24, 2021 | 2021         | TV-MA  | 2 Seasons | International TV Shows, TV Dramas, TV Mysteries | After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.                                   |\n",
    "| s3      | TV Show | Ganglands            | Julien Leclercq  | Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabiha Akkari, Sofia Lesaffre, Salim Kechiouche, Noureddine Farihi, Geert Van Rampelberg, Bakary Diombera                                   |               | September 24, 2021 | 2021         | TV-MA  | 1 Season  | Crime TV Shows, International TV Shows, TV Action & Adventure | To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war.                                     |\n",
    "| s4      | TV Show | Jailbirds New Orleans |                  |                                                                                                                                                        |               | September 24, 2021 | 2021         | TV-MA  | 1 Season  | Docuseries, Reality TV                        | Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.                                   |\n",
    "| s5      | TV Show | Kota Factory         |                  | Mayur More, Jitendra Kumar, Ranjan Raj, Alam Khan, Ahsaas Channa, Revathi Pillai, Urvi Singh, Arun Kumar                                                 | India        | September 24, 2021 | 2021         | TV-MA  | 2 Seasons | International TV Shows, Romantic TV Shows, TV Comedies | In a city of coaching centers known to train India’s finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read data from a CSV file on Google Cloud Storage (GCS), installing `google-cloud-storage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-storage) (2.40.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-storage) (2.24.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-storage) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-storage) (2.32.4)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-cloud-storage) (1.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (6.31.0rc2)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ2KWsYI_Msa"
   },
   "source": [
    "You can read data from a csv in GCS and then insert it into Spanner table using batch transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import csv\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def read_csv_from_gcs(bucket_name, file_name):\n",
    "    # Initialize a client\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Get the bucket\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # Get the blob (file)\n",
    "    blob = bucket.blob(file_name)\n",
    "\n",
    "    # Download the file\n",
    "    content = blob.download_as_string()\n",
    "\n",
    "    # Read CSV content\n",
    "    csv_data = content.decode(\"utf-8\")\n",
    "    csv_reader = csv.reader(csv_data.splitlines())\n",
    "\n",
    "    # Convert CSV reader to list of rows\n",
    "    rows = list(csv_reader)\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n",
      "Table created.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import spanner\n",
    "\n",
    "client = spanner.Client()\n",
    "instance = client.instance(instance_id)\n",
    "database = instance.database(database_id)\n",
    "table_name = \"netflix_titles\"\n",
    "\n",
    "operation = database.update_ddl(\n",
    "    [\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS {} (\n",
    "    show_id STRING(MAX) NOT NULL,\n",
    "    type STRING(MAX),\n",
    "    title STRING(MAX),\n",
    "    director STRING(MAX),\n",
    "    casta STRING(MAX),\n",
    "    country STRING(MAX),\n",
    "    date_added STRING(MAX),\n",
    "    release_year INT64,\n",
    "    rating STRING(MAX),\n",
    "    duration STRING(MAX),\n",
    "    listed_in STRING(MAX),\n",
    "    description STRING(MAX)\n",
    ") PRIMARY KEY (show_id)\"\"\".format(\n",
    "            table_name\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Waiting for operation to complete...\")\n",
    "operation.result(240)\n",
    "\n",
    "print(\"Table created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created multiplexed session.\n"
     ]
    }
   ],
   "source": [
    "rows = read_csv_from_gcs(\n",
    "    \"cloud-samples-data\", \"langchain/netflix_titles_compute_embeddings.csv\"\n",
    ")\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "for i in range(1, len(rows), batch_size):\n",
    "    with database.batch() as batch:\n",
    "        batch_rows = rows[i : i + batch_size]\n",
    "        batch.insert_or_update(\n",
    "            table=table_name,\n",
    "            columns=[\n",
    "                \"show_id\",\n",
    "                \"type\",\n",
    "                \"title\",\n",
    "                \"director\",\n",
    "                \"casta\",\n",
    "                \"country\",\n",
    "                \"date_added\",\n",
    "                \"release_year\",\n",
    "                \"rating\",\n",
    "                \"duration\",\n",
    "                \"listed_in\",\n",
    "                \"description\",\n",
    "            ],\n",
    "            values=batch_rows,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsGS80H04bDN"
   },
   "source": [
    "# **Use case 1: Spanner as a document loader**\n",
    "\n",
    "Now that you have data in your database, you are ready to use Spanner as a document loader. This means we will pull data from the database and load it into memory as documents. We can then feed these documents into the vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s-C0P-Oee69"
   },
   "source": [
    "You can see we also pass in a query, table_name and a list of columns. The query tells the loader what query to use to pull data. The \"content_columns\" argument refers to the columns that will be used as \"content\" in the document object we will later construct. The rest of the columns in that table will become the \"metadata\" associated with the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2SdFJT6Vece1"
   },
   "outputs": [],
   "source": [
    "from langchain_google_spanner.loader import SpannerLoader\n",
    "\n",
    "content_columns = [\"title\", \"director\", \"casta\", \"description\"]\n",
    "loader = SpannerLoader(\n",
    "    instance_id=instance_id,\n",
    "    database_id=database_id,\n",
    "    query=f\"SELECT * FROM {table_name};\",\n",
    "    content_columns=content_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsL-KFrmfuS1"
   },
   "source": [
    "Then let's run the function to pull our documents from out database using our document loader. You can see the first 5 documents from the database here. Nice, you just used  Spanner as a document loader!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4zTx-HLfwmW",
    "outputId": "da7239e4-710d-43ce-c004-520a0af9c79f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created multiplexed session.\n",
      "Created multiplexed session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8802 from the database. 5 Examples:\n",
      "page_content='The Starling Theodore Melfi Melissa McCarthy, Chris O'Dowd, Kevin Kline, Timothy Olyphant, Daveed Diggs, Skyler Gisondo, Laura Harrier, Rosalind Chao, Kimberly Quinn, Loretta Devine, Ravi Kapoor A woman adjusting to life after a loss contends with a feisty bird that's taken over her garden — and a husband who's struggling to find a way forward.' metadata={'show_id': 's10', 'type': 'Movie', 'country': 'United States', 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'PG-13', 'duration': '104 min', 'listed_in': 'Comedies, Dramas'}\n",
      "page_content='On the Verge Julie Delpy, Elisabeth Shue, Sarah Jones, Alexia Landeau, Mathieu Demy, Troy Garity, Timm Sharp, Giovanni Ribisi Four women — a chef, a single mom, an heiress and a job seeker — dig into love and work, with a generous side of midlife crises, in pre-pandemic LA.' metadata={'show_id': 's100', 'type': 'TV Show', 'country': 'France, United States', 'date_added': 'September 7, 2021', 'release_year': 2021, 'rating': 'TV-MA', 'duration': '1 Season', 'listed_in': 'TV Comedies, TV Dramas'}\n",
      "page_content='Stowaway Joe Penna Anna Kendrick, Toni Collette, Daniel Dae Kim, Shamier Anderson A three-person crew on a mission to Mars faces an impossible choice when an unplanned passenger jeopardizes the lives of everyone on board.' metadata={'show_id': 's1000', 'type': 'Movie', 'country': 'Germany, United States', 'date_added': 'April 22, 2021', 'release_year': 2021, 'rating': 'TV-MA', 'duration': '116 min', 'listed_in': 'Dramas, International Movies, Thrillers'}\n",
      "page_content='Wild Dog Ahishor Solomon Nagarjuna Akkineni, Dia Mirza, Saiyami Kher, Atul Kulakarni, Bilal Hussain, Ali Reza, Mayank Parakh A brash but brilliant Indian intelligence agent leads a covert operation to nab the mastermind behind a series of attacks threatening national security.' metadata={'show_id': 's1001', 'type': 'Movie', 'country': '', 'date_added': 'April 22, 2021', 'release_year': 2020, 'rating': 'TV-MA', 'duration': '126 min', 'listed_in': 'Action & Adventure, International Movies'}\n",
      "page_content='Oloibiri Curtis Graham Olu Jacobs, Richard Mofe-Damijo, William R. Moses, Taiwo Ajai-Lycett, Ifeanyi Williams, Ivie Okujaye, Dayton Sinkia, Bradley Gordon After drilling depletes a small village, a corporation finds more oil in the region, igniting tensions among the community.' metadata={'show_id': 's1002', 'type': 'Movie', 'country': 'Canada, Nigeria, United States', 'date_added': 'April 21, 2021', 'release_year': 2015, 'rating': 'TV-14', 'duration': '86 min', 'listed_in': 'Dramas, International Movies, Thrillers'}\n"
     ]
    }
   ],
   "source": [
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} from the database. 5 Examples:\")\n",
    "for doc in documents[:5]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9uLV3bs4noo"
   },
   "source": [
    "# **Use case 2: Spanner as Vector Store**\n",
    "Google Cloud Spanner supports 2 different algorithms that we have added vector store capabilities to:\n",
    "* K-Nearest Neighbors (KNN)\n",
    "* Approximate Nearest Neighbors (ANN)\n",
    "\n",
    "When your dataset is small, the K-Nearest Neighbors (KNN) algorithm works well, but with large datasets, you shall need to use Approximate Nearest Neighbors (ANN) because the latency and cost of a KNN search increases.\n",
    "However, we shall exhibit how to use both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfH8oQJ945Ko"
   },
   "source": [
    "### K-Nearest Neighbors (KNN) based vector store\n",
    "\n",
    "When the dataset is small, this algorithm is ideal\n",
    "Based on the documents that we loaded before, we want to create a table with a vector column as our vector store using the kNN algorithm. We will start it by intializing a vector table by calling the `init_vectorstore_table` function from our `SpannerVectorStore`. As you can see we list all of the columns for our metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_spanner import SpannerVectorStore, TableColumn\n",
    "\n",
    "sample_vector_table_name = \"movie_vector_table_samples\"\n",
    "\n",
    "\n",
    "SpannerVectorStore.init_vector_store_table(\n",
    "    instance_id=instance_id,\n",
    "    database_id=database_id,\n",
    "    table_name=sample_vector_table_name,\n",
    "    metadata_columns=[\n",
    "        TableColumn(\"show_id\", \"STRING(MAX)\"),\n",
    "        TableColumn(\"type\", \"STRING(MAX)\"),\n",
    "        TableColumn(\"country\", \"STRING(MAX)\"),\n",
    "        TableColumn(\"date_added\", \"STRING(MAX)\"),\n",
    "        TableColumn(\"release_year\", \"INT64\"),\n",
    "        TableColumn(\"rating\", \"STRING(MAX)\"),\n",
    "        TableColumn(\"duration\", \"STRING(MAX)\"),\n",
    "        TableColumn(\"listed_in\", \"STRING(MAX)\"),\n",
    "    ],\n",
    "    primary_key=\"langchain_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG6rwEuJLNIo"
   },
   "source": [
    "#### Try inserting the documents into the vector table\n",
    "\n",
    "Now we will create a vector_store object backed by our vector table in the Spanner database. Let's load the data from the documents to the vector table. Note that for each row, the embedding service will be called to compute the embeddings to store in the vector table. Pricing details can be found [here](https://cloud.google.com/vertex-ai/pricing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Wo4-7EYCIFF9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_vertexai.embeddings import VertexAIEmbeddings\n",
    "\n",
    "# Initialize the embedding service. In this case we are using version 005 of Vertex AI's textembedding model. In general, it is good practice to specify the model version used.\n",
    "embeddings_service = VertexAIEmbeddings(\n",
    "    model_name=\"text-embedding-005\", project=project_id\n",
    ")\n",
    "\n",
    "\n",
    "vector_store = SpannerVectorStore(\n",
    "    embedding_service=embeddings_service,\n",
    "    instance_id=instance_id,\n",
    "    database_id=database_id,\n",
    "    table_name=sample_vector_table_name,\n",
    "    metadata_columns=[\n",
    "        \"show_id\",\n",
    "        \"type\",\n",
    "        \"rating\",\n",
    "        \"country\",\n",
    "        \"date_added\",\n",
    "        \"release_year\",\n",
    "        \"duration\",\n",
    "        \"listed_in\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr1rP6KQ-8ag"
   },
   "source": [
    "Now let's try to put the documents data into the vector table. Here is a code example to load the first 5 documents in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CTks8Cy--93B"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5bbfe073-f577-4b8b-8378-1801ef00f42a',\n",
       " 'd7a5e63e-e244-4b64-9d70-536371af9c4f',\n",
       " 'da924eb2-de47-49eb-9f86-58cb25b6ec46',\n",
       " '1a8e8b84-e8f4-43bb-b85d-9d7bf8a964fa',\n",
       " '13631552-0b79-4ab1-8183-89419a51901b']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "docs_to_load = documents[:5]\n",
    "\n",
    "# ! Uncomment the following line to load all 8,800+ documents to the database vector table with calling the embedding service.\n",
    "# docs_to_load = documents\n",
    "\n",
    "ids = [str(uuid.uuid4()) for i in range(len(docs_to_load))]\n",
    "vector_store.add_documents(docs_to_load, ids, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29iztdvfL2BN"
   },
   "source": [
    "#### Import the rest of your data into your vector table\n",
    "\n",
    "You don't have to call the embedding service 8,800 times to load all the documents for the demo. Instead, we have prepared data with the all 8,800+ rows with pre-computed embeddings in a `.csv` file. Let's import data from csv directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FEe9El7QMjHi"
   },
   "outputs": [],
   "source": [
    "vector_store_rows = read_csv_from_gcs(\n",
    "    \"cloud-samples-data\", \"langchain/spanner/netflix_titles_embeddings.csv\"\n",
    ")\n",
    "\n",
    "for vector_store_row in vector_store_rows:\n",
    "    # Cast embedding column from String to Array<Float>\n",
    "    vector_store_row[2] = [float(x) for x in vector_store_row[2][1:-1].split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "\n",
    "for i in range(0, len(vector_store_rows), batch_size):\n",
    "    with database.batch() as batch:\n",
    "        batch_rows = vector_store_rows[i : i + batch_size]\n",
    "        batch.insert_or_update(\n",
    "            table=sample_vector_table_name,\n",
    "            columns=[\n",
    "                \"langchain_id\",\n",
    "                \"content\",\n",
    "                \"embedding\",\n",
    "                \"show_id\",\n",
    "                \"type\",\n",
    "                \"country\",\n",
    "                \"date_added\",\n",
    "                \"release_year\",\n",
    "                \"rating\",\n",
    "                \"duration\",\n",
    "                \"listed_in\",\n",
    "            ],\n",
    "            values=batch_rows,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfH8oQJ945Ko",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Approximate Nearest Neighbors (ANN) based vector store\n",
    "For this task, we shall pull in documents from a popular HackerNews post, insert them into our ANN based vector store and then use ANN to find the most relevent comments/content\n",
    "\n",
    "To create vector embeddings, we shall be using Google's Vertex AI text-embedding-005 model and then for all related queries, vectorize the query using our embedding service to then perform the search.\n",
    "\n",
    "Cloud Spanner allows for 3 different algorithms to be created with the vector search index and correspondingly used for the search:\n",
    "* APPROX_COSINE\n",
    "* APPROX_DOT_PRODUCT\n",
    "* APPROX_EUCLIDEAN_DISTANCE\n",
    "\n",
    "\n",
    "In this exhibit, we shall be using using `APPROX_COSINE`\n",
    "Our steps shall comprise:\n",
    "* Creating the text embedding service\n",
    "* Initializing the ANN vector store\n",
    "* Loading data from a popular HackerNews post\n",
    "* Adding the documents to the vector store\n",
    "* Searching by similarity_search, similarity_search_by_vector, max_marginal_relevance_search_with_score_by_vector\n",
    "* Deleting the inserted documents\n",
    "All the above using the langchain.VectorStore interface.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Create the embeddings\n",
    "We shall be pulling in an article from HackerNews and creating vector search embeddings using Google Vertex AI's textgecko3 model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_vertexai.embeddings import VertexAIEmbeddings\n",
    "\n",
    "embeddings_service = VertexAIEmbeddings(\n",
    "    model_name=\"text-embedding-005\", project=project_id\n",
    ")\n",
    "embedding_vector_size = 768\n",
    "vector_index_name = \"titles_index\"\n",
    "title_embedding_column = TableColumn(\n",
    "    name=\"title_embedding\", type=\"ARRAY<FLOAT64>\", is_null=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Initialize the vector store\n",
    "These steps allow you to decide the structure of your vector store table and then issue the creation DDL. In our case we are specifying that the vector search index will use the `COSINE` distance strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_spanner.vector_store import (\n",
    "    DistanceStrategy,\n",
    "    QueryParameters,\n",
    "    SpannerVectorStore,\n",
    "    TableColumn,\n",
    "    VectorSearchIndex,\n",
    ")\n",
    "\n",
    "table_name_ANN=\"movie_vector_table_samples_ANN\"\n",
    "\n",
    "SpannerVectorStore.init_vector_store_table(\n",
    "    instance_id=instance_id,\n",
    "    database_id=database_id,\n",
    "    table_name=table_name_ANN,\n",
    "    vector_size=embedding_vector_size,\n",
    "    id_column=\"row_id\",\n",
    "    metadata_columns=[\n",
    "        TableColumn(name=\"metadata\", type=\"JSON\", is_null=True),\n",
    "        TableColumn(name=\"title\", type=\"STRING(MAX)\", is_null=False),\n",
    "    ],\n",
    "    embedding_column=title_embedding_column,\n",
    "    secondary_indexes=[\n",
    "        VectorSearchIndex(\n",
    "            index_name=vector_index_name,\n",
    "            columns=[title_embedding_column.name],\n",
    "            nullable_column=True,\n",
    "            num_branches=1000,\n",
    "            tree_depth=3,\n",
    "            distance_type=DistanceStrategy.COSINE,\n",
    "            num_leaves=100000,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Acquire a handle to the vector store\n",
    "A handle to the vector store eases the ergonomics of remembering the distance strategy, vector index name and embedding column. ***Please note that to use ANN, you shall need to specify the algorithm and distance_strategy in your query_parameters***.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n"
     ]
    }
   ],
   "source": [
    "db = SpannerVectorStore(\n",
    "    instance_id=instance_id,\n",
    "    database_id=database_id,\n",
    "    table_name=table_name_ANN,\n",
    "    id_column=\"row_id\",\n",
    "    ignore_metadata_columns=[],\n",
    "    embedding_service=embeddings_service,\n",
    "    embedding_column=title_embedding_column,\n",
    "    metadata_json_column=\"metadata\",\n",
    "    vector_index_name=vector_index_name,\n",
    "    query_parameters=QueryParameters(\n",
    "        algorithm=QueryParameters.NearestNeighborsAlgorithm.APPROXIMATE_NEAREST_NEIGHBOR,\n",
    "        distance_strategy=DistanceStrategy.COSINE,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Add documents into the vector store\n",
    "Using LangChain's interface, you can populate the vector store with the posts from HackerNews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_docs 3\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "fruit_docs = [\n",
    "    Document(\n",
    "        page_content=\"Apple Granny Smith 150 0.99 1\",\n",
    "        metadata={\"title\": \"apple\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Banana Cavendish 200 0.59 0\",\n",
    "        metadata={\"title\": \"banana\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Orange Navel 80 1.29 1\",\n",
    "        metadata={\"title\": \"orange\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "ids = [str(uuid.uuid4()) for _ in range(len(fruit_docs))]\n",
    "db.add_documents(documents=fruit_docs, ids=ids)\n",
    "print(\"n_docs\", len(fruit_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Searching for documents by similarity searches\n",
    "We shall perform search by 4 different methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### similarity_search: your search query's embedding will be performed internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by similarity_search [Document(metadata={'title': 'orange'}, page_content='Orange Navel 80 1.29 1'), Document(metadata={'title': 'banana'}, page_content='Banana Cavendish 200 0.59 0')]\n"
     ]
    }
   ],
   "source": [
    "docs = db.similarity_search(\n",
    "    \"orange\",\n",
    "    k=2,\n",
    ")\n",
    "print(\"by similarity_search\", docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### similarity_by_vector_search: passing embeddings directly in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by direct vector_search [Document(metadata={'title': 'orange'}, page_content='Orange Navel 80 1.29 1'), Document(metadata={'title': 'banana'}, page_content='Banana Cavendish 200 0.59 0'), Document(metadata={'title': 'apple'}, page_content='Apple Granny Smith 150 0.99 1')]\n"
     ]
    }
   ],
   "source": [
    "embeds = embeddings_service.embed_query(\n",
    "    \"orange\",\n",
    ")\n",
    "docs = db.similarity_search_by_vector(\n",
    "    embeds,\n",
    "    k=3,\n",
    ")\n",
    "print(\"by direct vector_search\", docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_marginal_relevance_search_with_score_by_vector: passing embeddings directly in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by max_marginal_relevance_search [(Document(metadata={'title': 'orange'}, page_content='Orange Navel 80 1.29 1'), 0.3597469567919436), (Document(metadata={'title': 'apple'}, page_content='Apple Granny Smith 150 0.99 1'), 0.46334450128966564), (Document(metadata={'title': 'banana'}, page_content='Banana Cavendish 200 0.59 0'), 0.46136322919171247)]\n"
     ]
    }
   ],
   "source": [
    "docs = db.max_marginal_relevance_search_with_score_by_vector(\n",
    "    embeds,\n",
    "    k=3,\n",
    ")\n",
    "print(\"by max_marginal_relevance_search\", docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Clean up and delete the previously inserted documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted True\n"
     ]
    }
   ],
   "source": [
    "deleted = db.delete(documents=fruit_docs)\n",
    "print(\"deleted\", deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM_OFzZrQEPs"
   },
   "source": [
    "# **Use case 3: Spanner as Chat Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxqIPQtjDquk"
   },
   "source": [
    "Next we will add chat history (called “memory” in the context of LangChain) to our application so the LLM can retain context and information across multiple interactions, leading to more coherent and sophisticated conversations or text generation. We can use Spanner as “memory” storage in our application so that the LLM can use context from prior conversations to better answer the user’s prompts. First let's initialize Spanner as memory storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_spanner import (\n",
    "    SpannerChatMessageHistory,\n",
    ")\n",
    "\n",
    "message_table_name = \"message_store\"\n",
    "\n",
    "SpannerChatMessageHistory.create_chat_history_table(\n",
    "    instance_id=instance_id, database_id=database_id, table_name=message_table_name\n",
    ")\n",
    "\n",
    "chat_history = SpannerChatMessageHistory(\n",
    "    instance_id=instance_id,\n",
    "    database_id=database_id,\n",
    "    table_name=message_table_name,\n",
    "    session_id=\"my-test-session\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yuXYLTCl2K1"
   },
   "source": [
    "Here is an example of how you would add a user message and how you would add an ai message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDVoTWZal0ZF",
    "outputId": "aeb8c338-9f0d-4143-c09d-9c49478940e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello there. I'm a model and am happy to help!\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.add_user_message(\"Hi!\")\n",
    "chat_history.add_ai_message(\"Hello there. I'm a model and am happy to help!\")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0O9mta8RQ0v"
   },
   "source": [
    "# **Conversational RAG Chain backed by Spanner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0sEt05vD0E_"
   },
   "source": [
    "So far we've tested with using Spanner as document loader, Vector Store and Chat Memory. Now let's use it in the `ConversationalRetrievalChain`.\n",
    "\n",
    "We will build a chat bot that can answer movie related questions based on the vector search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "9ukjOO-sNQ8_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karthit/miniforge3/envs/langchain-spanner/lib/python3.11/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n",
      "Created multiplexed session.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_google_vertexai.embeddings import VertexAIEmbeddings\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_spanner import (\n",
    "    SpannerChatMessageHistory,\n",
    "    SpannerVectorStore,\n",
    "    SpannerLoader,\n",
    ")\n",
    "\n",
    "# Intialize the embedding service\n",
    "embeddings_service = VertexAIEmbeddings(\n",
    "    model_name=\"text-embedding-005\", project=project_id\n",
    ")\n",
    "\n",
    "# Intialize the Vector Store\n",
    "vector_table_name = sample_vector_table_name\n",
    "vector_store = SpannerVectorStore(\n",
    "    embedding_service=embeddings_service,\n",
    "    instance_id=instance_id,\n",
    "    database_id=database_id,\n",
    "    table_name=vector_table_name,\n",
    "    metadata_columns=[\n",
    "        \"show_id\",\n",
    "        \"type\",\n",
    "        \"country\",\n",
    "        \"rating\",\n",
    "        \"date_added\",\n",
    "        \"release_year\",\n",
    "        \"duration\",\n",
    "        \"listed_in\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Intialize the SpannerChatMessageHistory\n",
    "chat_history = SpannerChatMessageHistory(\n",
    "    instance_id=instance_id,\n",
    "    database_id=database_id,\n",
    "    session_id=\"my-test-session\",\n",
    "    table_name=message_table_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ytlz9D3LmcU7"
   },
   "source": [
    "Let's create a prompt for the LLM. Here we can add instructions specific to our application, such as \"Don't make things up\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "LoAHNdrWmW9W"
   },
   "outputs": [],
   "source": [
    "# Prepare some prompt templates for the ConversationalRetrievalChain\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Use all the information from the context and the conversation history to answer new question. If you see the answer in previous conversation history or the context. \\\n",
    "Answer it with clarifying the source information. If you don't see it in the context or the chat history, just say you \\\n",
    "didn't find the answer in the given data. Don't make things up.\n",
    "\n",
    "Previous conversation history from the questioner. \"Human\" was the user who's asking the new question. \"Assistant\" was you as the assistant:\n",
    "```{chat_history}\n",
    "```\n",
    "\n",
    "Vector search result of the new question:\n",
    "```{context}\n",
    "```\n",
    "\n",
    "New Question:\n",
    "```{question}```\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    ")\n",
    "condense_question_prompt_passthrough = PromptTemplate(\n",
    "    template=\"\"\"Repeat the following question:\n",
    "{question}\n",
    "\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsGe-bW5m0H1"
   },
   "source": [
    "Now let's use our vector store as a retreiver. Retreiver's in Langchain allow us to literally \"retrieve\" documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "1nI0xkJamvXt"
   },
   "outputs": [],
   "source": [
    "# Intialize retriever, llm and memory for the chain\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"lambda_mult\": 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3maZ8SLlneYJ"
   },
   "source": [
    "Now let's intialize our LLM, in this case we are using Vertex AI's \"gemini-pro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "VBWhg-ihnnxF"
   },
   "outputs": [],
   "source": [
    "llm = VertexAI(model_name=\"gemini-2.5-pro\", project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hN8mpXdtnocg"
   },
   "source": [
    "We clear our chat history, so that our application starts without any prior context to other conversations we have had with the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "1UkPcEpJno5Y"
   },
   "outputs": [],
   "source": [
    "chat_history.clear()\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    chat_memory=chat_history,\n",
    "    output_key=\"answer\",\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDAT2koSn8Mz"
   },
   "source": [
    "Now let's create a conversational retrieval chain. This will allow the LLM to use chat history in it's responses, meaning we can ask it follow up questions to our questions instead of having to start from scratch after each inquiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Fu8fKdEn8h8",
    "outputId": "abadf0d2-abcd-47a4-d598-45140205593f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What movie was Brad Pitt in?\n",
      "Answer: As mentioned in our previous conversation, I didn't find the answer in the given data.\n",
      "\n",
      "Question: How about Jonny Depp?\n",
      "Answer: As mentioned in our previous conversation, I didn't find the answer in the given data.\n",
      "\n",
      "Question: Are there movies about animals?\n",
      "Answer: Yes, as mentioned in our previous conversation, the movie \"The Starling\" is about an animal. Based on the context provided, its description is: \"A woman adjusting to life after a loss contends with a feisty bird that's taken over her garden — and a husband who's struggling to find a way forward.\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What movie was Brad Pitt in?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I didn't find the answer in the given data.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How about Jonny Depp?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I didn't find the answer in the given data.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Are there movies about animals?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes, based on the information provided in the context, the movie \"The Starling\" is about an animal. Its description is: \"A woman adjusting to life after a loss contends with a feisty bird that\\'s taken over her garden — and a husband who\\'s struggling to find a way forward.\"', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What movie was Brad Pitt in?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"As mentioned in our previous conversation, I didn't find the answer in the given data.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How about Jonny Depp?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"As mentioned in our previous conversation, I didn't find the answer in the given data.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Are there movies about animals?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes, as mentioned in our previous conversation, the movie \"The Starling\" is about an animal. Based on the context provided, its description is: \"A woman adjusting to life after a loss contends with a feisty bird that\\'s taken over her garden — and a husband who\\'s struggling to find a way forward.\"', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the ConversationalRetrievalChain\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    "    condense_question_prompt=condense_question_prompt_passthrough,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "\n",
    "# ask some questions\n",
    "q = \"What movie was Brad Pitt in?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "q = \"How about Jonny Depp?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "q = \"Are there movies about animals?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "# browser the chat history\n",
    "chat_history.messages"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "langchain-spanner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
